# ML3_Miniporj3_TsaiYunLi
This is a non-awarding, for-knowledge Kaggle practice for the application of generative adversarial networks (GANs) on photo style transfer. We are asked to use a model in the GANs family to learn from the provided Monet paintings and normal photos in order to 'monetify' the latter, i.e. to make the photos Monet-like. There are no paired examples in the datasets; that is, there is no direct, one-to-one correspondence between a photo and a Monet painting in the datasets. Analogically speaking, the datasets are 'unlabeled.'

There are several common GANs model candidates, including Deep Convolutional GANs (DCGANs), Conditional GANs, and CylceGAN. Among all of them, CycleGAN is most suitable for this Kaggle task, since it is an unsupervised, generative, deep learning model, specialized in traslating images from one domain X (the Monet paintings) to the other domain Y (the ordinary photos) without paired examples.

However, due to the very complex structure of a CycleGAN model and my first attempt of doing a project in this domain, I decided to perform a 'transfer learning' using the CycleGAN architecture with the optimal model hyperparameters and training tips described in both Wolf's 2018 and Shrivastava et al.'s 2016 articles. That is, my CycleGAN model to be built for this project would closely follow their 'blueprints,' not only to increase the possibility of completing the Kaggle task, but also to serve as a good opportunity for me to learn about and understand a CycleGAN model in more depth.

P.s. Please see links in the reference section for the Kaggle task overview and datasets, as well as the heavily cited Wolf 2018 and Shrivastava et al 2016 articles.

Conclusion:
The trained generator G of my CycleGAN model successfully transformed 31 photos in the photo dataset into Monet-style paintings. Ideally, I should visualize them with their original copy side by side; however, due to limited run time, I have to skip this evaluation process. Instead, I included a screenshot of these 31 'monetified' photos in my GitHub file named 'ML3Miniporj3_results.png' for your reference. You can visally evaluate the results of my project there.

Limiations:
There are lots of potential problems and limitations in this project. In the EDA section, I found out that the color distributions of the monet_dataset and the photo_dataset are quite different. This might influence the style transfer of the photos to monet-like ones but I do not know how to and did not mitigate this. During model training, I encountered a challenge for computer resources. I am only allowed to complete this project using the Kaggle notebook with a 5-hour run time limit. However, only after running the training loop for hours, I realized that it took about 6 hours just to complete one epoch! Ideally, I should run multiple epochs, which would exceed the 5-hour run time limit even more. This issue is likely caused by the very complex architecture of my CycleGAN model taken from Wolf 2018's article, the training tips from Shrivastava et al's 2016 article, as well as the relatively large size of the photo_dataset, which reulted in a 220 batch number with batch size set as 32. Since reducing the number of photos in the photo_dataset is not allowed, I could only reconstruct the architecture of my CylceGAN model, which unfortunately contradicts with my goal of learning about CylceGANs from the details in Wolf 2018 and Shrivastava et al 2016's articles. Therefore, I came to the decision of just running one epoch and not submitting to the Kaggle platform but including the 'images.zip' output in my Github repo. Please check it out there.

In general, I used the cited sources extensively, because understanding, building, and training a good CycleGAN model is pretty much very difficult for my first unsupervised generative model project. I added annotations and comments throughout this project, not only to clarify each step, but as a note for what I have learned through this research process.

Please let me know if there is a way to speed up the training loop without modifying my CycleGAN architecture and reducing the number of photos to be 'monetified' in the dataset. Refer to my GitHub repo to evaluate the results of this project. In addition, hope this can make up for the Kaggle submission problem.
